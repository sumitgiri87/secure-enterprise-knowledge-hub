# ─────────────────────────────────────────────────────────────
# SEKH - Environment Configuration
# Copy this file to .env and fill in your values
# NEVER commit .env to git!
# ─────────────────────────────────────────────────────────────

# ──────────────────────────────────────
# PHASE 1: Core API Settings (REQUIRED)
# ──────────────────────────────────────

# API authentication key
# Generate a strong key: python -c "import secrets; print(secrets.token_hex(32))"
API_KEY=your-secret-api-key-here

# Application environment
ENVIRONMENT=development   # development | staging | production

# Server settings
HOST=0.0.0.0
PORT=8000
DEBUG=true

# Logging
LOG_LEVEL=INFO
JSON_LOGS=true

# Rate limiting (requests per minute per user)
RATE_LIMIT_PER_MINUTE=60

# Token budget (tokens per day per user)
TOKEN_BUDGET_DAILY=100000

# ──────────────────────────────────────
# PHASE 2: LLM Integration
# Set LLM_ENABLED=true ONLY after adding at least one provider key
# ──────────────────────────────────────

# Master switch - set to true when you have API keys configured
LLM_ENABLED=false

# Default model to use
DEFAULT_LLM_MODEL=gpt-4
DEFAULT_MAX_TOKENS=1000
DEFAULT_TEMPERATURE=0.7

# LLM request timeout (seconds)
LLM_REQUEST_TIMEOUT=30

# ── OPTION A: Azure OpenAI (Recommended for enterprise) ──
# Get these from Azure Portal → Azure OpenAI → Keys and Endpoint
AZURE_OPENAI_API_KEY=your-azure-openai-key-here
AZURE_OPENAI_ENDPOINT=https://YOUR-INSTANCE.openai.azure.com
AZURE_OPENAI_API_VERSION=2024-02-15-preview
AZURE_OPENAI_DEPLOYMENT=gpt-4   # Your deployment name in Azure

# ── OPTION B: OpenAI Direct (Simpler for testing) ──
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-key-here

# ── OPTION C: AWS Bedrock (Claude/Llama models) ──
# Get from: AWS Console → IAM → Create Access Key
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key
AWS_REGION=us-east-1

# ── OPTION D: Anthropic Direct (Claude models) ──
# Get from: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=sk-ant-your-key-here

# ── OPTION E: GCP Vertex AI ──
GCP_PROJECT_ID=your-project-id
GCP_CREDENTIALS_PATH=/path/to/service-account.json

# ──────────────────────────────────────
# PHASE 3 (Future): RAG Pipeline
# ──────────────────────────────────────

# PINECONE_API_KEY=your-pinecone-key
# PINECONE_ENVIRONMENT=us-east-1-aws
# PINECONE_INDEX_NAME=sekh-knowledge-base

# ──────────────────────────────────────
# PHASE 4 (Future): Infrastructure
# ──────────────────────────────────────

# DATABASE_URL=postgresql://user:pass@localhost:5432/sekh
# REDIS_URL=redis://localhost:6379/0